
  For more complete information on NetPIPE, visit the webpage at:

http://www.scl.ameslab.gov/Projects/NetPIPE/

NetPIPE was originally developed by Quinn Snell, Armin Mikler,
John Gustafson, and Guy Helmer.  They developed the core of
NetPIPE along with MPI and TCP modules.

NetPIPE is currently being developed and maintained by Dave Turner with
help from several graduate students (Xuehua Chen, Adam Oline, 
Brian Smith, Bogdan Vasiliu).


Release 4.0 is a major rewrite of the internal code to allow 
NetPIPE to test using multiple pair-wise ping-pongs simultaneously.
For most systems, you must now specify a host file using <-H hostfile>
rather than using <-h remote_hostname>, or use the default 'nphosts' file.  
The pairs are chosen for maximum overlap, 
from the outside in (0 & np-1, 1 & np-2, ...).
You can reorder the MPI nodes using the <-H hostfile>.
Not all modules can currently use more than 1 pair.

**************************** NOTE ************************************
The original authors chose to define 1 megabit as 1024 * 1024 bits.
Since this tool measures network performance, which is based
on clockrates that are not dependent on page sizes, I have chosen
to change this to 1 Mbps = 1,000,000 bps.  This means that
performance can be directly compared to the maximum data rates
that a medium can support (1,000,000,000 bps that a Gigabit Ethernet card
can theoretically provide, for example).
Previous performance curves would have artificially been
5% low because of the choice of 1 Mbps = 1,048,576 bps.
**************************** NOTE ************************************

There is also a new theoretical module NPtheo that produces a 
performance curve calculated from the latency, max bandwidth,
and bandwidth of the transmission medium (and optionally a
rendezvous threshold).  It has proven very accurate in duplicating
the measured performance curve in most cases, and can provide
some insight into what limits the performance.

I am also currently adding the ability to measure the load
that the communication system puts on the CPU (-w for workload).
This work is still under development, so I'd advise not using
it at all at this time (it is probably fairly accurate for large
messages, and definitely inaccurate for small messages).

NetPIPE has always done several trials and reported the one with
the lowest time (best Mbps rate).  The np.out output now includes
the best, average, and worst Mbps rates in that order.  Plotting
the first 2 columns will still give you the same as previous versions.

There is a hardware cycle counter available for Intel and AMD chips.
Choose 'DEFS=USE_TSC' in the makefile to enable.  This allows very
accurate timings of even single ping-pong events (-R 1), and can be
used to gather statistical information on the variation in performance
by running many trials of single ping-pong events and looking at
the variation with the min, max, and average (use rangeplot).
The -Q option is a quick way of doing this since it runs 100 trials
of 1 ping-pong event each.  I have not seen too many instances where
there are fluctuations in the performance, even in areas where 
performance problems are occuring.  NOTE:  Some care is needed on
AMD systems.  The cycle counter is 32-bits only, so it flips over
about every 2 seconds.  That means all timings must be kept under
2 seconds when USE_TSC is enabled.  On Pentium 4 systems, there is
a 64-bit cycle counter so there are no similar problems.

Performing multiple memcpy's can now be done as well.  Since each
Opteron processor actually has its own local memory, the aggregate bandwidth
achievable with N Opteron procs should be N times that of a single one.
Opteron's achieve their SMP-like behavior by sharing data via hypertransport.
This adds latency when accessing remote memory, which can be measured using
the -mx flag (requires the numactl patch to be installed).
The -mi flag will interleave memory between the processors.
The memcpy module was altered to only do a memcpy on SendData, not
RecvData.  This gets all cache effects out of the -I runs.
The memcpy module can also be compiled to measure performance
through a pipe within each process.

Release 3.7 adds a bi-directional (-2) mode to allow data to be sent
in both directions simultaneously. This has been tested with the
TCP, MPI, MPI-2, IB, and GM modules.  You can also now test
synchronous MPI communications MPI_SSend/MPI_SRecv using (-S).
A launch utility (nplaunch) allows you to launch NPtcp, NPgm, 
NPib, and NPpvm from one side using ssh to start the remote executible.

Version 3.6 adds the ability to test with and without cache effects,
and the ability to offset both the source and destination buffers.
A memcpy module has also been added.

Release 3.5 removes the CPU utilization measurements.  Getrusage is
probably not very accurate, so a dummy workload will eventually be
used instead.
The streaming mode has also been fixed.  When run at Gigabit speeds,
the TCP window size would collapse limit performance of subsequent
data points.  Now we reset the sockets between trials to prevent this.
We have also added in a module to evaluate memory copy rates.
-n now sets a constant number of repeats for each trial.
-r resets the sockets between each trial (automatic for streaming).

Release 3.3 includes an Infiniband module for the Mellanox VAPI.
It also has an integrity check (-i), which is still being developed.

Version 3.2 includes additional modules to test
PVM, TCGMSG, SHMEM, and MPI-2, as well as the GM, GPSHMEM, ARMCI, and LAPI
software layers they run upon.  

If you have problems or comments, please email netpipe@scl.ameslab.gov

____________________________________________________________________________

NetPIPE Network Protocol Independent Performance Evaluator, Release 2.3
Copyright 1997, 1998 Iowa State University Research Foundation, Inc.

This program is free software; you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation.  You should have received a copy of the
GNU General Public License along with this program; if not, write to the
Free Software Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
____________________________________________________________________________


Building NetPIPE
----------------

NetPIPE requires an ANSI C compiler.  You are on your own for 
installing the various libraries that NetPIPE can be used to
test.

Review the provided makefile and change any necessary settings, such
as the CC compiler or CFLAGS flags, required extra libraries, and PVM
library & include file pathnames if you have these communication
libraries.  Alternatively, you can specify these changes on the 
make command line.  The line below would compile the NPtcp module
using the icc compiler instead of the default cc compiler.

  make CC=icc tcp

Compile NetPIPE with the desired communication interface by using:

  make mpi        (this will use the default MPI on the system)
  make pvm        (you may need to set some paths in the makefile)
  make mpi2       (this will test 1-sided MPI_Put() functions)
  make shmem      (1-sided library for Cray and SGI systems)

  make tcp
  make gm         (for Myrinet cards, you will need to set some paths)
  make shmem      (1-sided library for Cray and SGI systems)
  make gpshmem    (SHMEM interface for other machines)
  make armci      (still under development)
  make lapi       (for the IBM SP)
  make ib         (for Mellanox Infiniband adapters, uses VAPI layer)
  make memcpy     (uses memcpy to copy data between buffers within each process)
  make MP_memcpy  (uses an optimized copy in MP_memcpy.c to copy data between 
                   buffers.  This requires icc or gcc 3.x.)
  make pipe       (push data thru a pipe on each process)
  make theo       (generate a theoretical curve given Tlat, Rmax, Rmedium)


Running NetPIPE
---------------

   NetPIPE will dump its output to the screen by default and also
to the np.out.  The following parameters can be used to change how
NetPIPE is run, and are in order of their general usefulness.

	-b: specify send and receive TCP buffer sizes e.g. "-b 32768"
            This can make a huge difference for Gigabit Ethernet cards.
            You may need to tune the OS to set a larger maximum TCP
            buffer size for optimal performance.

        -B: Bi-directional communications.  Transmit in both directions
            simultaneously.

        -H: <-H hostfile> specifies the host file for TCP, and may be
            used for MPI to specify the order of the nodes to alter
            how they get paired up.

        -O: specify transmit and optionally receive buffer offsets <-O 1,3>

	-l: lower bound (start value for block size) e.g. "-l 1"

	-u: upper bound (stop value for block size) e.g. "-u 1048576"

	-o: specify output filename e.g. "-o output.txt"

        -z: for MPI, receive messages using ANYSOURCE

        -g: MPI-2: use MPI_Get() instead of MPI_Put()

        -f: MPI-2: do not use a fence call (may not work for all packages)

        -I: Invalidate cache: Take measures to eliminate the effects cache
            has on performance.

	-A: specify buffers alignment e.g. "-A 4096"
            buffers are page-aligned by default

	-a: asynchronous receive (a.k.a. pre-posted receive)
            May not have any effect, depending on your implementation
        
        -P: Preposts all receives before measuring performance.
            Normally only one receive is preposted at a time with -a

        -p: set or turn off perturbations of the message size (3 by default)

        -i: Integrity check: Check the integrity of data transfer instead
            of performance

        -s: stream option (default mode is "ping pong")
            If this option is used, it must be specified on both
            the sending and receiving processes

        -S: Use synchronous sends/receives for MPI.

   TCP
   ---

      Compile NetPIPE using 'make tcp'

      local_host>  nplaunch NPtcp -H hostfile [options]

            (if ssh/rsh is not present, you may start manually)

      local_host>  NPtcp -H hostfile [options]
      remote_host> NPtcp -H hostfile [options]

            (Example for multiple pairwise bidirectional tests)

      local_host>  cat tcphosts
                     slam
                     zombie
                     wakka
                     rikku

      local_host>  nplaunch NPtcp -n 4 -H tcphosts -B [options]


   MPI - general comments
   ---

      Don't specify <-n nprocs> since this comes from MPI_Comm_size().
      You can reorder the node pairs using the hostfile <-H hostfile>.
      The order taken is first and last, and working inward.

   MPICH
   -----

      Install MPICH
      Compile NetPIPE using 'make mpi'
      use p4pg file or edit mpich/util/mach/mach.{ARCH} file
          to specify the machines to run on
      mpirun [-nolocal] -np 2 NPmpi [options]
      'setenv P4_SOCKBUFSIZE 256000' can make a huge difference for
           MPICH on Unix systems.

   LAM/MPI    (comes on the RedHat Linux distributions now)
   -------

      Install LAM
      Compile NetPIPE using 'make mpi'
      put the machine names into a lamhosts file
      'lamboot -v -b lamhosts' to start the lamd daemons
      mpirun -np 2 [-O] NPmpi [options]
      The -O parameter avoids data translation for homogeneous systems.

   MPI/Pro     (commercial version)
   -------

      Install MPI/Pro
      Compile NetPIPE using 'make mpi'
      put the machine names into /etc/machines or a local machine file
      mpirun -np 2 NPmpi [options]

   MP_Lite      (A lightweight version of MPI)
   -------

      Install MP_Lite  (http://www.scl.ameslab.gov/Projects/MP_Lite/)
      Compile NetPIPE using 'make MP_Lite'
      mprun -np 2 -h {host1} {host2} NPmplite [options]

   PVM
   ---

      Install PVM  (comes on the RedHat distributions now)
      Set the PVM paths in the makefile if necessary.
      Compile NetPIPE using 'make pvm'
      use the 'pvm' utility to start the pvmd daemons
        type 'pvm' to start it  (this will also start pvmd on the local_host)
        pvm> help           --> lists all commands
        pvm> add remote_host --> will start a pvmd on a machine called 'host2'
        pvm> quit           --> when you have all the pvmd machines started
      remote_host> NPpvm [options]
      local_host>  NPpvm -h remote_host [options]
                       OR
      local_host>  nplaunch NPpvm -h remote_host [options]
      Changing PVMDATA in netpipe.h and PvmRouteDirect in pvm.c can
        effect the performance greatly.

   MPI-2
   -----

      Install the MPI package
      Compile NetPIPE using 'make mpi2'
      Follow the directions for running the MPI package from above
      The MPI_Put() function will be tested with fence calls by default.
      Use -g to test MPI_Get() instead, or -f to do MPI_Put() without
        fence calls (will not work with LAM).

   SHMEM
   -----

      Must be run on a Cray or SGI system that supports SHMEM calls.
      Compile NetPIPE using 'make shmem'
      (Xuehua, fill out the rest)

   GPSHMEM  (a Generalized Portable SHMEM library) (gpshmem.c in development)
   -------

      Ask Ricky or Krzysztof for help :).

   GM       (test the raw performance of GM on Myrinet cards)
   --

      Install the GM package and configure the Myrinet cards
      Compile NetPIPE using 'make gm'

      remote_host> NPgm [options]
      local_host>  NPgm -h remote_host [options]

                       OR

      local_host>  nplaunch NPgm -h remote_host [options]

   LAPI
   ----

      The LAPI module currently only works for 2 processors.

      These directions may be specific to the IBM SP at NERSC

      Compile NetPIPE using 'make lapi'

      To run interactively at NERSC:

      Set environment variable MP_MSG_API to lapi
        e.g. 'setenv MP_MSG_API lapi', 'export MP_MSG_API=lapi'
      Run NPlapi with '-procs 2' to tell the parallel environment you
        want 2 nodes.  Use any other options that are applicable to NetPIPE.

      To submit a batch job at NERSC:

      Grab an example batch file from nersc.gov under Seaborg
                use '#@ network.LAPI  = csss, not_shared , US'
                tasks_per_node: Number of tasks to be run on each node
                node:           Number of nodes to run on
                (Use a combination of the above two options to determine
                 how NetPIPE runs.  Use 1 task per node and 2 nodes to run
                 benchmark between nodes.  Use 2 tasks per node and 1 node
                 to run benchmark on single node)

      Use whatever command-line options are appropriate for NetPIPE

      Submit the job with the command 'llsubmit batchLapi'
      Check status of all your jobs with 'llqs -u <user>'

   ARMCI
   -----   
   
      Install the ARMCI package
      Compile NetPIPE using 'make armci'
      Follow the directions for running the MPI package from above
      If running on interfaces other than the default, create a file
        called armci_hosts, containing two lines, one for each hostname,
	then run package. 

   InfiniBand
   ----------

      This module requires a common file system and ssh (or change to
      rsh in bin/nplaunch).

      Install Mellanox Infiniband adapters and software.

      Make sure the adapters are up and running (e.g. Check that the 
        Mellanox-supplied bandwidth/latency program, perf_main, works, if 
        you have it).

      Some useful commands may be:
         vapi start          (run on each host to load the IB modules)
         minism InfiniHost0  (run on one host to run the subnet manager)
         > x
         vapi status         (to check for active status on a host)

      Compile NetPIPE using 'make ib' (The environment variable MTHOME needs
        to be set to the directory containing the include and lib directories
        for the Mellanox software).

      bin/nplaunch NPib -H nphosts [-options]

      nphosts should contain the list of hostnames, one per line

      Other options:  Use -m to select mtu size for InfiniBand adapter.
        Valid values are 256, 512, 1024, 2048, 4096.  Default is 1024.

   Theoretical curve
   -----------------

      This module generates a theretical performance curve given
   the small message latency Tlat, the maximum bandwidth Rmax, and
   the theoretical bandwidth of the transmission medium Rmed.  You
   can also provide the Rendezvous threshold using -R #.  Choosing
   Ethernet or InfiniBand sets the sizes for the packet header and
   MTU.  If you want other than the defaults, you'll need to change
   them in theo.c for now and recompile.

   NPtheo -F E,250,900,1000

      This generates a theoretical curve for Ethernet with a latency
  of 250 microseconds and a max bandwidth of 900 Mbps for Gigabit 
  Ethernet (1000 Mbps).

  NPtheo -F I,4.0,7200,8000 -R 1024

     This generates a theoretical curve for InfiniBand with a latency
  of 4.0 us and a max bandwidth of 7.2 Gbps with a Rendezvous threshold
  at 1024 Bytes.

     In addition to the theoretical curve, NPtheo also prints out
  some intermediate calculations for Th, the time spent transmitting
  the packet header, and Tp, a size-dependent overhead that can come
  from a variety of sources.  The size-dependent overheads prevent
  the throughput from reaching Rmed.  The small-message latency
  also prevents the performance from reaching the maximum bandwidth
  (it lowers the perfomance in the intermediate range).


   Memory copy tests
   -----------------

   make memcpy
   make ntcopy        --> non-temporal memory copy routine for Pentium 4
   make amdcopy       --> AMD's optimized copy routine
   make mmxcopy       --> adapted from _mmx_copy in Linux kernel
   make pagecopy      --> adapted from fast_copy_page in Linux kernel

   NPmemcpy [options]
       or
   nplaunch NPmemcpy -n #procs [options]

      The memcpy module simply does a memcpy between 2 buffers.  You should see
   major cache effects.  Another common feature seen is a spiking from the
   gcc memcpy function.  Better performance is seen when the buffer size is
   divisible by 4, since the glibc memcpy then copies 4-bytes at a time.
   If not divisible by 4, it reverts to copying byte-by-byte.  The glibc 
   memcpy routine should be fixed so that it copies any bytes up to 4-byte
   alignment 1 at a time, then does 4-byte copies of the bulk, followed by
   1-byte copies of any remaining data.  This is what the Intel memcpy does.

      The main memory bandwidth (right side of graph) is different when 
   measured using cache effects (default) and cache invalidation (-I).
   I have not identified the exact cause yet (TLB cache misses, etc.).

      Since Opteron systems and Itaniums in Altix boxes each have their own 
   memory, memory performance is different depending on the memory policy
   chosen.  You can use the numactl command to bind NPmemcpy to a given
   proc, and bind the memory to a given memory bank (or interleaved), to
   test the latency and bandwidth differences.  To do this, you must have
   the numactl patch installed (try 'numactl --show' to see) and have
   the bios set properly so that each CPU is treated as a node
   (try 'numactl --hardware').  The commands below would do a memcpy
   from local memory, remote memory, and interleaved respectively.

      numactl --cpubind=0 --membind=1 NPmemcpy -I
      numactl --cpubind=0 --membind=0 NPmemcpy -I
      numactl --cpubind=0 --interleave=0,1 NPmemcpy -I

      For running multiple NPmemcpy's simultaneously, use nplaunch with
   a '-mx' flag will tell the script to launch using numactl to force use 
   of your neighbor's memory.  A '-mi' flag will force memory to be 
   interleaved by page between the processors.  A '-ml' will force use
   of local memory.

      The optimized memory copy routines (ntcopy, amdcopy, mmxcopy, pagecopy)
   are available only on some architectures (primarily x86 at this point).
   The ntcopy does particularly well on Intel Pentium 4 based chips, 
   resulting in as much of a doubling of performance.  All these routines
   gain some benefit by prefetching data and making use of additional
   registers such as the MMX and XMM registers.

   Pipe throughput
   ---------------

   make pipe
   NPpipe [options]
       or
   nplaunch NPpipe -n #procs [options]   (takes hosts from the nphosts file)

      This opens a pipe within each process and pushes data through in
   chunks that are limited by the system to around 1 page (4096 Bytes).
   The performance is poorer than a memcpy due to the added overhead
   of doing the write/read calls for every page of data.

  
Interpreting the Results
------------------------

NetPIPE generates a np.out file by default, which can be renamed using the
-o option.  This file contains 3 columns:  the number of bytes, the 
throughput in Mbps, and the round trip time divided by two.
The first 2 columns can therefore be used to produce a throughput vs
message size graph.

The screen output contains this same information, plus the test number
and the number of ping-pong's involved in the test.

>more np.out
       1 0.136403   0.00005593
       2 0.274586   0.00005557
       3 0.402104   0.00005692
       4 0.545668   0.00005593
       6 0.805053   0.00005686
       8 1.039586   0.00005871
      12 1.598912   0.00005726
      13 1.700719   0.00005832
      16 2.098007   0.00005818
      19 2.340364   0.00006194

   For bidirectional mode, the bandwidth is the aggregate bandwidth
which will hopefully be about twice the unidirectional bandwidth.
   Multiple overlapping pairwise tests with the bidirectional
mode can be used to fully stress an Ethernet switch, or to overload
a communication link in an MPP to see if it can handle more bandwidth
than a single pair of nodes can generate.  Multiple unidirectional
ping-pongs may not tell you much, since they may get out of phase.
   For multiple pairwise tests, it is again the aggregate bandwidth
that is reported, which is hopefully npairs times the bidirectional
bandwidth for 1 pair.  The time reported, and used in the bandwidth
calculation, is that of the last pair to finish, which will produce
the worst case result for the latency and bandwidth (which I think
is the most appropriate to be looking at).  

Invalidating Cache
------------------

The -I switch can be used to reduce the effects cache has on performance.  
Without the switch, NetPIPE tests the performance of communicating 
n-byte blocks by reading from an n-byte buffer on one node, sending data 
over the communications link, and writing to an n-byte buffer on the other 
node.  For each block size, this trial will be repeated x times, where x
typically starts out very large for small block sizes, and decreases as the
block size grows.  The same buffers on each node are used repeatedly, so
after the first transfer the entire buffer will be in cache on each node,
given that the block-size is less than the available cache.  Thus each transfer
after the first will be read from cache on one end and written into cache on
the other.  Depending on the cache architecture, a write to main memory may
not occur on the receiving end during the transfer loop.

While the performance measurements obtained from this method are certainly 
useful, it is also interesting to use the -I switch to measure performance 
when data is read from and written to main memory.  In order to facilitate 
this, large pools of memory are allocated at startup, and each n-byte transfer 
comes from a region of the pool not in cache.  Before each series of n-byte 
transfers, every byte of a large dummy buffer is individually accessed in 
order to flush the data for the transfer out of cache.  After this step, the 
first n-byte transfer comes from the beginning of the large pool, the second 
comes from n-bytes after the beginning of the pool, and so on (note that stride
between n-byte transfers will depend on the buffer alignment setting).  In this
way we make sure each read is coming from main memory.

On the receiving end data is written into a large pool in the same fashion 
that it was read on the transmitting end.  Data will first be written into 
cache.  What happens next depends on the cache architecture, but one case is 
that no transfer to main memory occurs, YET.  For moderately large block 
sizes, however, a large number of transfer iterations will cause reuse of 
cache memory.  As this occurs, data in the cache location to be replaced must 
be written back to main memory, so we incur a performance penalty while we 
wait for the write.

In summary, using the -I switch gives worst-case performance (i.e. all data
transfers involve reading from or writing to memory not in cache) and not
using the switch gives best-case performance (i.e. all data transfers involve
only reading from or writing to memory in cache).  Note that other combinations,
such as reading from memory in cache and writing to memory not in cache, would
give intermediary results.  We chose to implement the methods that will measure
the two extremes.

Changes needed
--------------

 - we need to replace the getrusage stuff from version 2.4 with a dummy
   workload

